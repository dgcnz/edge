{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch 2 Export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.export 101\n",
    "\n",
    "The main idea of `torch.export` is that it translates an Eager Mode PyTorch model into a graph-based intermediate representation called *Export IR*. This allows compiler backends to take this IR and further transform and optimize it for a target device. A general overview of the process is shown in the figure [below](torchexport).\n",
    "\n",
    ":::{figure-md} torchexport\n",
    "<img src=\"compilation.png\" alt=\"torch.export\" width=70%>\n",
    "\n",
    "PyTorch 2 Export\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This IR needs to fulfill a couple of properties for it to be useful to compilers. For example:\n",
    "1. Operators have to be general enough for backends to notice patterns and optimize them: Many runtimes have specialized kernels  for common operators like convolutions or even more complex ones like a `conv2 + batchnorm` (operator fusion). If the IR reduces all operators to sums, products and views, noticing these patterns becomes too hard.\n",
    "2. The number of operators has to be small enough for the backend to implement all of them. \n",
    "3. Operators have to be functional, that is, without side effects. For example: If two functions read and modify the same parameters, the order of execution matters and the compiler has to be careful when parallelizing them.\n",
    "\n",
    "Notice that properties 1 and 2 are in conflict with each other. The more operators we have, the more expressive the IR is, but the harder it is to implement all of them. This is a trade-off that the PyTorch team has to balance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For now, let's get some practical intuition with an example.\n",
    "\n",
    "Let's use the following simple network:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing with torch.export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(3, 6, 5)\n",
    "        self.fc1 = nn.Linear(6 * 14 * 14, 10)\n",
    "        self.fc2 = nn.Linear(6 * 14 * 14, 10)\n",
    "        self.register_buffer(\"mask\", torch.randn(6, 14, 14) > 0.5)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.conv(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, (2, 2))\n",
    "        x = x * self.mask\n",
    "        x = torch.flatten(x, 1)\n",
    "        y = self.fc1(x)\n",
    "        z = self.fc2(x)\n",
    "        y = F.relu(y) \n",
    "        z = F.relu(z)\n",
    "        return z, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 3, 32, 32) \n",
    "ep: torch.export.ExportedProgram = torch.export.export(SimpleNet(), (x,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.export.save(ep, \"simple_net.pt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cu124",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
